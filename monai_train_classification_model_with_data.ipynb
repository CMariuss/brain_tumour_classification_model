{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af97f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "from monai.networks.nets import DenseNet121\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import functional as TF\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImage, Resize, ScaleIntensity, ToTensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07931464",
   "metadata": {},
   "source": [
    "### Setting the device - cuda / cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3b7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd81c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset base path\n",
    "base_dir = 'dataset'\n",
    "train_dir = os.path.join(base_dir, 'training')\n",
    "test_dir = os.path.join(base_dir, 'testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce3436",
   "metadata": {},
   "source": [
    "### Defining class names and index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37eeb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names and index\n",
    "class_names = sorted(os.listdir(train_dir))\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde3911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image paths and labels\n",
    "def get_image_paths_and_labels(folder):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for cls_name in class_names:\n",
    "        cls_folder = os.path.join(folder, cls_name)\n",
    "        files = glob.glob(os.path.join(cls_folder, '*.jpg'))\n",
    "        image_paths.extend(files)\n",
    "        labels.extend([class_to_idx[cls_name]] * len(files))\n",
    "    return image_paths, labels\n",
    "\n",
    "train_paths, train_labels = get_image_paths_and_labels(train_dir)\n",
    "test_paths, test_labels = get_image_paths_and_labels(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b59f0",
   "metadata": {},
   "source": [
    "### MONAI-style transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c03767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONAI-style transforms\n",
    "transform = Compose([\n",
    "    Resize((224, 224)),\n",
    "    ScaleIntensity(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6dbad",
   "metadata": {},
   "source": [
    "### Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3408fff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load as grayscale\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')\n",
    "        image = TF.to_tensor(image)  # shape: [1, H, W]\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08156ac",
   "metadata": {},
   "source": [
    "### Datasets and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8393c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets and loaders\n",
    "train_ds = BrainTumorDataset(train_paths, train_labels, transform)\n",
    "test_ds = BrainTumorDataset(test_paths, test_labels, transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df6c4a",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4c908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = DenseNet121(spatial_dims=2, in_channels=1, out_channels=num_classes).to(device)\n",
    "\n",
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d6be6",
   "metadata": {},
   "source": [
    "### Prepare lists to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce83216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the lists\n",
    "epochs_num_list = []\n",
    "loss_list = []\n",
    "accuracy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13110d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Total: {total} | Corect: {correct}')\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    # Store result data\n",
    "    epochs_num_list.append(epoch + 1)\n",
    "    loss_list.append(epoch_loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), f'monai_tumor_classifier_121_densenet_{n_epochs}_epochs.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9672b1",
   "metadata": {},
   "source": [
    "### Store results data in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f6d532",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Epoch': epochs_num_list,\n",
    "    'Loss': loss_list,\n",
    "    'Accuracy': accuracy_list,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0e222",
   "metadata": {},
   "source": [
    "### Save results in a CVS file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'training_{n_epochs}_epochs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
